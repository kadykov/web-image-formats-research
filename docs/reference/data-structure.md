---
title: "Data directory structure"
description: "Layout and file naming conventions for the `data/` directory and pipeline outputs."
---

This reference describes the data directory organization and file storage conventions.

## Overview

All research data is stored in the `data/` directory, organized by pipeline stage:

```text
data/
├── datasets/        # Raw image datasets
├── preprocessed/    # Preprocessed images
├── encoded/         # Encoded images
├── metrics/         # Quality measurement results
└── analysis/        # Analysis outputs
```

## data/datasets/

**Purpose**: Raw, unmodified datasets from external sources.

**Contents**:

- Downloaded image datasets
- Original, pristine images
- No modifications or preprocessing

**Generated by**: `scripts/fetch_dataset.py`

**Structure**:

```text
data/datasets/
├── DIV2K_valid/
│   ├── 0801.png
│   ├── 0802.png
│   └── ...
└── DIV2K_train/
    ├── 0001.png
    ├── 0002.png
    └── ...
```

**Typical Size**: 500MB - 10GB

**Git Status**: Ignored (`.gitignore`)

## data/preprocessed/

**Purpose**: Images after preprocessing transformations, organized by study and resolution.

**Contents**:

- Resized images
- Format normalization
- Study-specific preprocessing

**Generated by**: `scripts/run_pipeline.py` (as part of encoding studies with per-encoder `resolution` config)

**Structure**:

```text
data/preprocessed/
└── resolution-impact/      # Study ID
    ├── r640/
    │   ├── 0801.png
    │   └── ...
    ├── r960/
    │   └── ...
    ├── r1280/
    │   └── ...
    ├── r1920/
    │   └── ...
    └── r2048/
        └── ...
```

**Naming Conventions**:

- Study ID as top-level directory
- Resolution prefix: `r<pixels>` (longest edge in pixels)
- Image names match source dataset images

**Typical Size**: Similar to datasets (varies by resolution)

**Git Status**: Ignored

**Notes**:

- Preprocessing is done automatically during encoding studies
- Images are generated on-demand when an encoder specifies `resolution` in its config
- Raw datasets remain pristine for different preprocessing strategies

## data/encoded/

**Purpose**: Compressed images in target formats with various settings, organized by study.

**Contents**:

- JPEG at multiple quality levels
- WebP at multiple quality levels
- AVIF with various speed/quality/chroma combinations
- JPEG XL at different effort levels
- Study metadata and results

**Generated by**: `scripts/run_pipeline.py`

**Structure**:

```text
data/encoded/
├── avif-quality-sweep/
│   ├── results.json           # Encoding results metadata
│   └── avif/
│       ├── original/          # Images at original resolution
│       │   ├── 0801_q30_420_s4.avif
│       │   ├── 0801_q35_420_s4.avif
│       │   └── ...
│       └── r1920/             # Images preprocessed to 1920px
│           └── ...
├── format-comparison/
│   ├── results.json
│   ├── jpeg/
│   │   ├── 0801_q75.jpg
│   │   └── ...
│   ├── webp/
│   │   └── ...
│   ├── avif/
│   │   └── ...
│   └── jxl/
│       └── ...
└── resolution-impact/
    └── ...
```

**Naming Conventions**:

- Study ID as top-level directory (e.g., `avif-quality-sweep`)
- Format name as subdirectory (e.g., `avif/`, `jpeg/`)
- Resolution subdirectories: `original/` or `r<pixels>/` (e.g., `r1920/`)
- Image names include parameters: `<name>_q<quality>_<chroma>_s<speed>.<ext>`

**results.json Schema**:

```json
{
  "study_id": "avif-quality-sweep",
  "study_name": "AVIF Quality Sweep",
  "dataset": {
    "id": "div2k-valid",
    "path": "data/datasets/DIV2K_valid",
    "image_count": 10
  },
  "timestamp": "2026-02-10T21:52:04.948827+00:00",
  "encodings": [
    {
      "source_image": "data/datasets/DIV2K_valid/0801.png",
      "original_image": "data/datasets/DIV2K_valid/0801.png",
      "encoded_path": "data/encoded/avif-quality-sweep/avif/original/0801_q30_420_s4.avif",
      "format": "avif",
      "quality": 30,
      "chroma_subsampling": "420",
      "speed": 4,
      "file_size": 89804,
      "width": 2040,
      "height": 1356,
      "source_file_size": 4717456
    }
  ]
}
```

**Typical Size**: 2-5× dataset size (multiple formats and qualities)

**Git Status**: Ignored

## data/metrics/

**Purpose**: Quality measurements and compression statistics, organized by study.

**Contents**:

- SSIMULACRA2 scores
- Butteraugli distances
- PSNR/SSIM values
- File sizes and compression ratios
- Study metadata

**Generated by**: `scripts/run_pipeline.py`

**Structure**:

```text
data/metrics/
├── avif-quality-sweep/
│   └── quality.json
├── format-comparison/
│   └── quality.json
└── resolution-impact/
    └── quality.json
```

**quality.json Schema**:

```json
{
  "study_id": "avif-quality-sweep",
  "study_name": "AVIF Quality Sweep",
  "dataset": {
    "id": "div2k-valid",
    "path": "data/datasets/DIV2K_valid",
    "image_count": 10
  },
  "encoding_timestamp": "2026-02-10T21:52:04.948827+00:00",
  "timestamp": "2026-02-11T10:30:00.000000+00:00",
  "measurements": [
    {
      "source_image": "data/datasets/DIV2K_valid/0801.png",
      "original_image": "data/datasets/DIV2K_valid/0801.png",
      "encoded_path": "data/encoded/avif-quality-sweep/avif/original/0801_q30_420_s4.avif",
      "format": "avif",
      "quality": 30,
      "chroma_subsampling": "420",
      "speed": 4,
      "file_size": 89804,
      "width": 2040,
      "height": 1356,
      "source_file_size": 4717456,
      "ssimulacra2": 68.5,
      "psnr": 38.2,
      "ssim": 0.945,
      "butteraugli": 1.25,
      "measurement_error": null
    }
  ]
}
```

**Quality Metrics Interpretation**:

- **SSIMULACRA2**: Higher is better (~100 = lossless, 70-90 = good, <30 = poor)
- **PSNR**: Higher is better in dB (>40dB = excellent, 30-40dB = good)
- **SSIM**: Higher is better, 0-1 scale (>0.95 = excellent)
- **Butteraugli**: Lower is better (<1.0 = excellent, <1.5 = good, >3.0 = poor)

## data/analysis/

**Purpose**: Final analysis outputs for presentation and reporting.

**Contents** (Planned):

- Rate-distortion curves
- Quality comparison plots
- Statistical summaries
- Final reports

**Generated by**: `scripts/analyze_results.py` (future)

**Structure** (Proposed):

```text
data/analysis/
├── plots/
│   ├── rate_distortion_ssimulacra2.png
│   ├── rate_distortion_butteraugli.png
│   ├── format_comparison.png
│   └── ...
├── reports/
│   ├── summary.html
│   └── detailed.pdf
└── statistics/
    ├── mean_scores.csv
    └── confidence_intervals.csv
```

**Typical Size**: <100MB

**Git Status**: Ignored (but can selectively commit key plots)

## Disk Space Management

### Typical Space Requirements

| Directory | Typical Size | Notes |
|-----------|-------------|-------|
| `datasets/` | 500MB - 10GB | Depends on which datasets are fetched |
| `preprocessed/` | Similar to datasets | Multiple preprocessing variants |
| `encoded/` | 2-5× preprocessed | Multiple formats and quality levels |
| `metrics/` | <100MB | JSON/CSV files are compact |
| `analysis/` | <100MB | Plots and reports |
| **Total** | **20-50GB** | For full pipeline execution |

### Cleanup Strategies

Use the `just` commands for safe, consistent cleanup:

**Clean specific study** (preserves datasets):

```bash
just clean-study avif-quality-sweep
```

**Clean all study data** (preserves datasets):

```bash
just clean-studies
```

**Full cleanup** (removes everything including datasets):

```bash
just clean-all-data
```

**Clean then run a study**:

```bash
just clean-study avif-quality-sweep
just pipeline avif-quality-sweep
```

**Manual cleanup examples**:

If you need more fine-grained control:

```bash
# Keep up to encoding (re-measure and re-analyze)
rm -rf data/metrics/* data/analysis/*

# Clean specific format in a study
rm -rf data/encoded/format-comparison/jpeg/*     # Re-encode JPEG only
rm -rf data/encoded/format-comparison/avif/*     # Re-encode AVIF only
```

## File Naming Conventions

### Images

- Use original image IDs/names where possible
- Maintain consistent naming across pipeline stages
- Example: `0001.png` → `0001.jpg`, `0001.webp`, `0001.avif`

### Metrics Files

- Use descriptive names: `ssimulacra2.json`, not `metrics1.json`
- Include format/version if multiple: `metrics_v2.json`
- Use `.json` for hierarchical data, `.csv` for tabular

### Analysis Files

- Include metric name in plots: `rate_distortion_ssimulacra2.png`
- Use timestamps for reports: `report_2026-02-10.html`
- Group related files in subdirectories

## Git Ignore Configuration

All data directories are git-ignored except `.gitkeep` files:

```gitignore
data/datasets/*
!data/datasets/.gitkeep
data/preprocessed/*
!data/preprocessed/.gitkeep
data/encoded/*
!data/encoded/.gitkeep
data/metrics/*
!data/metrics/.gitkeep
data/analysis/*
!data/analysis/.gitkeep
```

This preserves directory structure while ignoring large data files.

## Backup Recommendations

### What to Backup

1. **Source code and configs**: Version controlled (git)
2. **Raw datasets**: Can be re-downloaded, but saves time
3. **Metrics**: Small and valuable (can regenerate but time-consuming)
4. **Key analysis plots**: For presentations and papers

### What NOT to Backup

1. **Preprocessed images**: Can regenerate from datasets
2. **Encoded images**: Can regenerate from preprocessed
3. **Intermediate analysis**: Can regenerate from metrics

### Backup Strategy

```bash
# Backup essentials (code + configs)
git push

# Backup datasets (if you modified them or source is unreliable)
tar czf datasets_backup.tar.gz data/datasets/

# Backup metrics (small and valuable)
tar czf metrics_backup.tar.gz data/metrics/

# Backup key plots
tar czf plots_backup.tar.gz data/analysis/plots/
```

## Data Lineage

Understanding the data flow helps with debugging and reproducibility:

```text
datasets → [preprocessed] → encoded → metrics → analysis
   ↓             ↓             ↓          ↓         ↓
                            config/studies/<study>.json
                                    ↓
                            encoding results.json
                                    ↓
                            quality results.json
```

**Pipeline Flow**:

1. **Dataset**: Raw images downloaded from external sources
2. **Preprocessing** (optional): Images resized according to study config
3. **Encoding**: Images encoded per study configuration → `results.json`
4. **Quality Measurement**: Metrics measured from `results.json` → `quality.json`
5. **Analysis** (future): Visualizations and reports from `quality.json`

Each stage:

- Reads configuration from `config/studies/<study-id>.json`
- Reads input from previous stage's output
- Writes to its own directory under `data/<stage>/<study-id>/`
- Can be re-run independently if previous stage outputs exist

## See Also

- [Configuration Files Reference](configuration) - Config file formats
- [Data Architecture Explanation](../explanation/data-architecture) - Design decisions
- [How to Fetch Datasets](../how-to/fetch-datasets) - Practical usage
