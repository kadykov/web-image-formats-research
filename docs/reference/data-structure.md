# Reference: Data Directory Structure

This reference describes the data directory organization and file storage conventions.

## Overview

All research data is stored in the `data/` directory, organized by pipeline stage:

```text
data/
├── datasets/        # Raw image datasets
├── preprocessed/    # Preprocessed images
├── encoded/         # Encoded images
├── metrics/         # Quality measurement results
└── analysis/        # Analysis outputs
```

## data/datasets/

**Purpose**: Raw, unmodified datasets from external sources.

**Contents**:

- Downloaded image datasets
- Original, pristine images
- No modifications or preprocessing

**Generated by**: `scripts/fetch_dataset.py`

**Structure**:

```text
data/datasets/
├── DIV2K_valid/
│   ├── 0801.png
│   ├── 0802.png
│   └── ...
└── DIV2K_train/
    ├── 0001.png
    ├── 0002.png
    └── ...
```

**Typical Size**: 500MB - 10GB

**Git Status**: Ignored (`.gitignore`)

## data/preprocessed/

**Purpose**: Images after preprocessing transformations.

**Contents** (Planned):

- Resized images
- Color space conversions
- Format normalization
- Cropped or filtered images

**Generated by**: `scripts/preprocess_images.py` (future)

**Structure** (Proposed):

```text
data/preprocessed/
├── 2048x2048/
│   ├── 0001.png
│   └── ...
├── 1024x1024/
│   └── ...
└── original_aspect/
    └── ...
```

**Typical Size**: Similar to datasets

**Git Status**: Ignored

**Notes**:

- Keep separate from datasets since preprocessing is lossy
- Multiple preprocessing variants may exist
- Raw datasets remain pristine for different preprocessing strategies

## data/encoded/

**Purpose**: Compressed images in target formats with various settings.

**Contents** (Planned):

- JPEG at multiple quality levels
- WebP at multiple quality levels
- AVIF with various speed/quality combinations
- JPEG XL at different effort levels

**Generated by**: `scripts/encode_images.py` (future)

**Structure** (Proposed):

```text
data/encoded/
├── jpeg/
│   ├── q10/
│   │   ├── 0001.jpg
│   │   └── ...
│   ├── q20/
│   └── ...
├── webp/
│   ├── q10/
│   ├── q20/
│   └── ...
├── avif/
│   ├── speed0_q10/
│   ├── speed0_q20/
│   ├── speed6_q10/
│   └── ...
└── jxl/
    ├── e1_d0.5/
    ├── e1_d1.0/
    └── ...
```

**Naming Conventions**:

- Format name as top-level directory
- Settings as subdirectories (e.g., `q10` for quality 10)
- Image names match source images

**Typical Size**: 2-5× preprocessed size (multiple formats and qualities)

**Git Status**: Ignored

## data/metrics/

**Purpose**: Quality measurements and compression statistics.

**Contents** (Planned):

- SSIMULACRA2 scores
- Butteraugli distances
- PSNR/SSIM values
- File sizes and compression ratios
- Encoding time and parameters
- Metadata about measurements

**Generated by**: `scripts/measure_quality.py` (future)

**Structure** (Proposed):

```text
data/metrics/
├── ssimulacra2.json
├── butteraugli.json
├── psnr_ssim.json
├── compression_ratios.csv
└── encoding_times.csv
```

**File Formats**:

- JSON for hierarchical data
- CSV for tabular data suitable for Pandas

**Typical Size**: <100MB

**Git Status**: Ignored (but small enough to optionally commit)

**Example JSON Structure**:

```json
{
  "image_id": "0001",
  "original": "data/preprocessed/2048x2048/0001.png",
  "measurements": [
    {
      "format": "jpeg",
      "quality": 10,
      "encoded_file": "data/encoded/jpeg/q10/0001.jpg",
      "file_size": 45678,
      "ssimulacra2": 45.2,
      "butteraugli": 1.23,
      "psnr": 28.5,
      "ssim": 0.876,
      "encoding_time": 0.123
    }
  ]
}
```

## data/analysis/

**Purpose**: Final analysis outputs for presentation and reporting.

**Contents** (Planned):

- Rate-distortion curves
- Quality comparison plots
- Statistical summaries
- Final reports

**Generated by**: `scripts/analyze_results.py` (future)

**Structure** (Proposed):

```text
data/analysis/
├── plots/
│   ├── rate_distortion_ssimulacra2.png
│   ├── rate_distortion_butteraugli.png
│   ├── format_comparison.png
│   └── ...
├── reports/
│   ├── summary.html
│   └── detailed.pdf
└── statistics/
    ├── mean_scores.csv
    └── confidence_intervals.csv
```

**Typical Size**: <100MB

**Git Status**: Ignored (but can selectively commit key plots)

## Disk Space Management

### Typical Space Requirements

| Directory | Typical Size | Notes |
|-----------|-------------|-------|
| `datasets/` | 500MB - 10GB | Depends on which datasets are fetched |
| `preprocessed/` | Similar to datasets | Multiple preprocessing variants |
| `encoded/` | 2-5× preprocessed | Multiple formats and quality levels |
| `metrics/` | <100MB | JSON/CSV files are compact |
| `analysis/` | <100MB | Plots and reports |
| **Total** | **20-50GB** | For full pipeline execution |

### Cleanup Strategies

**Full cleanup**:

```bash
rm -rf data/datasets/* data/preprocessed/* data/encoded/* data/metrics/* data/analysis/*
```

**Keep datasets only** (re-run pipeline from scratch):

```bash
rm -rf data/preprocessed/* data/encoded/* data/metrics/* data/analysis/*
```

**Keep up to encoding** (re-measure and re-analyze):

```bash
rm -rf data/metrics/* data/analysis/*
```

**Clean specific stage**:

```bash
rm -rf data/encoded/jpeg/*     # Re-encode JPEG only
rm -rf data/encoded/avif/*     # Re-encode AVIF only
```

## File Naming Conventions

### Images

- Use original image IDs/names where possible
- Maintain consistent naming across pipeline stages
- Example: `0001.png` → `0001.jpg`, `0001.webp`, `0001.avif`

### Metrics Files

- Use descriptive names: `ssimulacra2.json`, not `metrics1.json`
- Include format/version if multiple: `metrics_v2.json`
- Use `.json` for hierarchical data, `.csv` for tabular

### Analysis Files

- Include metric name in plots: `rate_distortion_ssimulacra2.png`
- Use timestamps for reports: `report_2026-02-10.html`
- Group related files in subdirectories

## Git Ignore Configuration

All data directories are git-ignored except `.gitkeep` files:

```gitignore
data/datasets/*
!data/datasets/.gitkeep
data/preprocessed/*
!data/preprocessed/.gitkeep
data/encoded/*
!data/encoded/.gitkeep
data/metrics/*
!data/metrics/.gitkeep
data/analysis/*
!data/analysis/.gitkeep
```

This preserves directory structure while ignoring large data files.

## Backup Recommendations

### What to Backup

1. **Source code and configs**: Version controlled (git)
2. **Raw datasets**: Can be re-downloaded, but saves time
3. **Metrics**: Small and valuable (can regenerate but time-consuming)
4. **Key analysis plots**: For presentations and papers

### What NOT to Backup

1. **Preprocessed images**: Can regenerate from datasets
2. **Encoded images**: Can regenerate from preprocessed
3. **Intermediate analysis**: Can regenerate from metrics

### Backup Strategy

```bash
# Backup essentials (code + configs)
git push

# Backup datasets (if you modified them or source is unreliable)
tar czf datasets_backup.tar.gz data/datasets/

# Backup metrics (small and valuable)
tar czf metrics_backup.tar.gz data/metrics/

# Backup key plots
tar czf plots_backup.tar.gz data/analysis/plots/
```

## Data Lineage

Understanding the data flow helps with debugging and reproducibility:

```text
datasets → preprocessed → encoded → metrics → analysis
   ↓           ↓            ↓          ↓         ↓
config/    config/      config/    config/    config/
datasets   preprocess   encoding   quality    analysis
  .json      .json        .json      .json      .json
```

Each stage:

- Reads from the previous stage
- Applies transformations defined in config
- Writes to its own directory
- Can be re-run independently

## See Also

- [Configuration Files Reference](configuration.md) - Config file formats
- [Data Architecture Explanation](../explanation/data-architecture.md) - Design decisions
- [How to Fetch Datasets](../how-to/fetch-datasets.md) - Practical usage
